---
title: "flat_minimal_package.Rmd empty"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)
```

<!--
 You need to run the 'description' chunk in the '0-dev_history.Rmd' file before continuing your code there.
-->

```{r development-load}
# Load already included functions if relevant
pkgload::load_all(export_all = FALSE)
```

# Internal funtions

```{r function-is_arrow_con}
#' Validate if is an arrow table
#'
#' @param x An object
#'
#' @return A boolean variable
is_arrow_con <- function(x){
  inherits(x, "ArrowObject") | 
    inherits(x, "arrow_dplyr_query")
}
```


# Bussiness Understanding

## simulate_trips

```{r function-simulate_trips}

#' Simulates a day of work
#' 
#' This function sample from a data.frame or arrow connection all the trips needed
#' to complete the a working day form taxi driver.
#'
#' @param arrow_con a data.frame or arrow connection with trips to sample from, with the columns described below.
#' @param start_datetime a date with an associated time when the taxi driver start to work
#' @param start_zone a number to select to the starting zone
#' @param minutes_next_trip an integer to define the limit time needed before extending the filters
#' @param end_datetime a date with an associated time when the taxi driver stop looking for new trips
#' @param valid_end_zones a vector of number defining all possible zones to drive
#' @param closest_zone a named vector pointing the closest zone from the taxi driver is waiting for a need trip in order to start a trip
#' @param borough_zones a data.frame with the integer column LocationID with all possible zone ids and the list column id_list with contain all other zones ids related to the LocationID's borough
#' 
#' @details
#' `arrow_con` must has the following columns
#' 
#' | "Column Name"| "class" |
#' |--------------|---------|
#' | year | integer |
#' | month| integer |
#' | PULocationID | integer|
#' | DOLocationID | integer|
#' | request_datetime | POSIXct POSIXt|
#' | dropoff_datetime | POSIXct POSIXt|
#' | driver_pay | numeric|
#' | tips | numeric|
#' 
#' @return A data.frame
#' @export
#'
#' @examples
simulate_trips <- function(arrow_con,
                           start_datetime,
                           start_zone,
                           minutes_next_trip,
                           end_datetime,
                           valid_end_zones,
                           closest_zone,
                           borough_zones){
  
  expected_columns <- c(
    # Parquet document
    "year", "month",
    # Start and ending zones
    "PULocationID", "DOLocationID",
    # Start and ending date times
    "request_datetime", "dropoff_datetime",
    # Money related in the trip
    "driver_pay", "tips"
  )
  
  stopifnot("You are missing one or more expected column in the arrow_con" = 
              all(expected_columns %in% names(arrow_con)))
  
  
  # Transforming minutes to period class
  minutes_next_trip <- lubridate::minutes(minutes_next_trip)
  
  # For the first trip
  current_time <- start_datetime
  current_zone <- start_zone

  # An empty table to bind the results
  done_trips <- data.frame(
    s_PULocationID = vector("integer"),
    s_DOLocationID = vector("integer"),
    s_request_datetime = vector("double") |> lubridate::as_datetime(),
    s_dropoff_datetime = vector("double") |> lubridate::as_datetime(),
    s_driver_pay = vector("double"),
    s_tips = vector("double")
  )

  # We need to keep adding trips until reaching the end_time 
  while(current_time <= end_datetime){
  
  # Defining time needed to wait
  wait_limit_datetime <- current_time + minutes_next_trip

   # Filter all trips that meet the expected conditions
    # Remove any row that don't meet expectations
    simulated_trip <-
      arrow_con |>
      dplyr::filter(year == lubridate::year(current_time),
                    month == lubridate::month(current_time),
                    PULocationID %in% current_zone,
                    DOLocationID %in% valid_end_zones,
                    request_datetime >= current_time,
                    request_datetime <= wait_limit_datetime) |>
        
        # Add the prefix s_ to each column
        dplyr::select(s_PULocationID = PULocationID,
                      s_DOLocationID = DOLocationID,
                      s_request_datetime = request_datetime,
                      s_dropoff_datetime = dropoff_datetime,
                      s_driver_pay = driver_pay,
                      s_tips = tips)
    
    # If arrow we need to collect
    if(is_arrow_con(arrow_con)){
      
      simulated_trip <- dplyr::collect(simulated_trip)
    
    }
    
    # Once we have alternatives to select from can select one trip
    simulated_trip <- dplyr::slice_sample(simulated_trip, n = 1L) 

    # If we can not find any trip in the zone and time defined
    # we can move update the current time try to find trip in the closest zone
    if(length(current_zone) == 1L && nrow(simulated_trip) == 0L){

      current_time <- current_time + minutes_next_trip
      current_zone <- c(current_zone, closest_zone[as.character(current_zone)])

    # If we couldn't find any trip to the closest zone
    # we can open the trip to any zone of the borough
    # after updating the current_time
    }else if(length(current_zone) > 1L && nrow(simulated_trip) == 0L){

      current_time <- current_time + minutes_next_trip
      current_zone <- c(
        current_zone,
        borough_zones[borough_zones$LocationID == current_zone[1L], ][["id_list"]][[1L]]
      )

    }else{
      
      # Updating starting point for next trip
      current_time <- simulated_trip$s_dropoff_datetime
      current_zone <- simulated_trip$s_DOLocationID

      # Adding the trip to final result
      done_trips <- 
        dplyr::bind_rows(done_trips, simulated_trip)
      
    }

  }

  # Returning all trips
  return(done_trips)

}

```

```{r example-simulate_trips, echo=FALSE, eval=FALSE}

# Defining some zone context
valid_zones <- 1:3
closest_zones <- c(2L, 1L, 2L)
names(closest_zones) <- valid_zones
borough_zones <- data.frame(
  LocationID = valid_zones,
  id_list = I(list(valid_zones, valid_zones, valid_zones))
)

# Defining start point
start_datetime <- lubridate::make_datetime(2023L, 5L, 18L, 8L)
start_zone <- 1L

# Let's check trips from at 3 levels
# 1. Starting in the same zone
# 2. Starting in the closest zone
# 3. Starting in the farthest zone
valid_trips <- data.frame(
  year = 2023L,
  month = 5L,
  PULocationID = c(1L, 2L, 3L),
  DOLocationID = c(3L, 1L, 1L),
  request_datetime = c(
   start_datetime + lubridate::minutes(2L),
   start_datetime + lubridate::minutes(20L + 7L),
   start_datetime + lubridate::minutes(37L + 14L)
  ),
  dropoff_datetime = c(
   start_datetime + lubridate::minutes(20L),
   start_datetime + lubridate::minutes(37L),
   lubridate::make_datetime(2023L, 5L, 18L, 9L, 1L)
  ),
  driver_pay = 10,
  tips = 2 
)

simulate_trips(valid_trips,
               start_datetime = start_datetime,
               start_zone = start_zone,
               minutes_next_trip = 6L,
               end_datetime = start_datetime + lubridate::hours(1L),
               valid_end_zones = valid_zones,
               closest_zone = closest_zones,
               borough_zones = borough_zones)

```

```{r tests-simulate_trips}

# Defining some zone context
valid_zones <- 1:3
closest_zones <- c(2L, 1L, 2L)
names(closest_zones) <- valid_zones
borough_zones <- data.frame(
  LocationID = valid_zones,
  id_list = I(list(valid_zones, valid_zones, valid_zones))
)

# Defining start point
start_datetime <- lubridate::make_datetime(2023L, 5L, 18L, 8L)
start_zone <- 1L

# Let's check trips from at 3 levels
# 1. Starting in the same zone
# 2. Starting in the closest zone
# 3. Starting in the farthest zone
valid_trips <- data.frame(
  year = 2023L,
  month = 5L,
  PULocationID = c(1L, 2L, 3L),
  DOLocationID = c(3L, 1L, 1L),
  request_datetime = c(
   start_datetime + lubridate::minutes(2L),
   start_datetime + lubridate::minutes(20L + 7L),
   start_datetime + lubridate::minutes(37L + 14L)
  ),
  dropoff_datetime = c(
   start_datetime + lubridate::minutes(20L),
   start_datetime + lubridate::minutes(37L),
   lubridate::make_datetime(2023L, 5L, 18L, 9L, 1L)
  ),
  driver_pay = 10,
  tips = 2 
)

# Defining 2 invalid trips
# 1. The trip goes after the 6 min in same zone
# 2. The trip is too far from second iteration
trips_to_omit <- data.frame(
  year = 2023L,
  month = 5L,
  PULocationID = c(1L, 3L),
  DOLocationID = c(3L, 1L),
  
  request_datetime = c(
   start_datetime + lubridate::minutes(2L + 6L),
   start_datetime + lubridate::minutes(20L + 7L)
  ),
  dropoff_datetime = c(
   start_datetime + lubridate::minutes(26L),
   start_datetime + lubridate::minutes(37L)
  ),
  driver_pay = 10,
  tips = 2 
)

result <- 
  simulate_trips(rbind(valid_trips, trips_to_omit),
                 start_datetime = start_datetime,
                 start_zone = start_zone,
                 minutes_next_trip = 6L,
                 end_datetime = start_datetime + lubridate::hours(1L),
                 valid_end_zones = valid_zones,
                 closest_zone = closest_zones,
                 borough_zones = borough_zones)


testthat::test_that("The simulation is taking the correct options",{
  
  testthat::expect_true(
   nrow(result) == 3L
  )
  
})


testthat::test_that("Missing column stop is working",{
  
  testthat::expect_error({
    simulate_trips(valid_trips[!names(valid_trips) %in% c("driver_pay", "tips")],
                   start_datetime = start_datetime,
                   start_zone = start_zone,
                   minutes_next_trip = 6L,
                   end_datetime = start_datetime + lubridate::hours(1L),
                   valid_end_zones = valid_zones,
                   closest_zone = closest_zones,
                   borough_zones = borough_zones) 
  })
  
})

```


## BaseLineSimulation

```{r function-BaseLineSimulation, eval=FALSE, echo=FALSE}
#' BaseLineSimulation
#'
#' Trips returned after running the simulation.
#'
#' @format A data frame of 10 variables:
#' \describe{
#'   \item{ simulation_day }{ Sample date }
#'   \item{ s_PULocationID }{ TLC Taxi Zone in which the trip began }
#'   \item{ s_DOLocationID }{ TLC Taxi Zone in which the trip ended }
#'   \item{ s_request_datetime }{ Date and time when passenger requested to be picked up }
#'   \item{ s_dropoff_datetime }{ The date and time of the trip drop-off }
#'   \item{ s_driver_pay }{ Total driver pay (not including tolls or tips and net of commission, surcharges, or taxes) }
#'   \item{ s_tips }{ Total amount of tips received from passenger }
#'   \item{ PULocationID }{ Start zone of the simulation day }
#'   \item{ hours_to_work }{ The number of hour to work in the simulation day }
#'   \item{ start_time }{ Start date and time for the simulation day }
#' }
#' @source TLC Trip Record Data
"BaseLineSimulation"
```


# EDA functions

## count_pct

```{r function-count_pct}
#' Counts rows based con columns provided
#' 
#' It counts the number rows where each unique value repeated in the columns 
#' selected arranging there results in descent order and adds a percentage 
#' column after collecting the results from `arrow`.
#'
#' @param x A lazy data frame arrow connection.
#' @param ... Variables to group by
#' @param wt  If a variable, computes sum(wt) for each group.
#' @param sort If TRUE, will show the largest groups at the top.
#' @param digits Integer indicating the number of decimal places
#'
#' @return A data.frame
#' @export
#'
#' @examples
count_pct <- function(x, ..., wt = NULL,  sort = TRUE, digits = 3L){
  
  grouping_vars_expr <- rlang::quos(...)
  wt_expr <- rlang::enquo(wt)
  
  counted_data <-
    if(!is.null(wt_expr)){
      dplyr::count(x,!!! grouping_vars_expr , wt = {{wt}}, sort = sort)
    }else{
      dplyr::count(x,!!! grouping_vars_expr, sort = sort)
    }
  
  
  if(is_arrow_con(x)){
    counted_data <- dplyr::collect(counted_data)
  }
  
  data.table::setDT(counted_data)
  
  counted_data[, pct := round(n / sum(n), digits)]
  
  counted_data[, pct_cumulative := cumsum(pct)]
  
  return(counted_data[])

}
```

```{r example-count_pct}
set.seed(1234)

arrow_con <- 
  data.frame(char1 = sample(LETTERS[1:3], 100, replace = TRUE),
             char2 = sample(LETTERS[4:6], 100, replace = TRUE)) |>
  arrow::arrow_table()

# One var
count_pct(arrow_con, char1)

# Two vars
dt1 <-count_pct(arrow_con, char1, char2)
dt1

# You can use the wt function
count_pct(dt1, char1, wt = n)
```


```{r test-count_pct}
set.seed(1234)

arrow_con <- 
  data.frame(char1 = sample(LETTERS[1:3], 100, replace = TRUE),
             char2 = sample(LETTERS[4:6], 100, replace = TRUE)) |>
  arrow::arrow_table()

# One var
dt1 <- count_pct(arrow_con, char1)

# Two vars
dt2 <-
  count_pct(arrow_con, char1, char2) |>
  count_pct(char1, wt = n)

testthat::test_that("wt is working",{
  
  expect_equal(
    dt2, dt1
  )
  
})

```



## add_zone_description

```{r function-add_zone_description}
#' Create a data.frame to show the zones
#' 
#' It translate the start and end ids with more detailed information.
#'
#' @param dt Main data.table to be use.
#' @param zone_dt A data.table with zones from data dictionary.
#' @param start_id_col A string indicating the id to be used as starting point.
#' @param end_id_col A string indicating the id to be used as ending point.
#' @param keep_dt_id_cols If `FALSE`, the columns indicated the `start_id_col` and `end_id_col` will be removed.
#' @param zone_id_col A string indicating the id related to each location in the `zone_dt` table.
#' 
#' @return A data.table
#' @export
add_zone_description <- function(dt, 
                                 zone_dt,
                                 start_id_col,
                                 end_id_col,
                                 zone_id_col,
                                 keep_dt_id_cols = FALSE){
  
  ## assertive programming
  
  # Validate if any col name is missing
  stopifnot("start_id_col must be length 1 character vector" =
              length(start_id_col) == 1L && is.character(start_id_col))
  stopifnot("end_id_col must be length 1 character vector" =
              length(end_id_col) == 1L && is.character(end_id_col))
  stopifnot("zone_id_col must be length 1 character vector" =
              length(zone_id_col) == 1L && is.character(zone_id_col))
  
  # Data must be formatted in data.tables
  stopifnot("dt must be a data.table" = data.table::is.data.table(dt))
  stopifnot("zone_dt must be a data.table" = data.table::is.data.table(zone_dt))
  
  # Validating that the tables has the columns needed
  stopifnot("dt must have start_id_col and end_id_col columns" = all(c(start_id_col, end_id_col) %chin% names(dt)))
  stopifnot("zone_dt must have zone_id_col" = zone_id_col %chin% names(zone_dt))
  
  # zone_dt can no have duplicated zones
  stopifnot("All zone_dt rows must be unique" = uniqueN(zone_dt[[zone_id_col]]) == nrow(zone_dt))

  ## Copying the data to avoid side effects
  zone_tb_end <- data.table::copy(zone_dt)
  zone_tb_start <- data.table::copy(zone_dt)
  
  ## Changing zone_td col names
  
  # Changing id column
  data.table::setnames(zone_tb_end, zone_id_col, "end_id")
  data.table::setnames(zone_tb_start, zone_id_col, "start_id")
  
  # Adding the correct prefix the remaining columns
  remaining_cols <- names(zone_tb_end)[-1]
  remaining_cols_lower <- tolower(remaining_cols)
  data.table::setnames(zone_tb_end, 
                       remaining_cols,
                       paste0("end_", remaining_cols_lower))
  data.table::setnames(zone_tb_start,
                       remaining_cols,
                       paste0("start_", remaining_cols_lower))
  
  
  ## Creating the table to export
  
  # Adding ending information
  joined_dt <- zone_tb_end[dt, on = c("end_id" = end_id_col)]
  joined_dt <- zone_tb_start[joined_dt, on = c("start_id" = start_id_col)]
  
  # Dealing with col id names
  if(keep_dt_id_cols){
    
    # Restoring col id names
    data.table::setnames(joined_dt,
                         c("start_id", "end_id"),
                         c(start_id_col, end_id_col))
    
  }else{
    
    # Removing original id columns
    joined_dt[, c("start_id", "end_id") := NULL]
    
  }
  
  return(joined_dt[])

}
```

```{r examples-add_zone_description}
set.seed(123)

base_data <- data.table::data.table(
  start_id = 1:5,
  end_id = sample.int(5, 5),
  value = seq(50, length.out = 5, by = 50)
)

zone_description <- data.table::data.table(
  id = 1:5,
  City = LETTERS[1:5],
  Zone = tail(LETTERS, 5L)
)

add_zone_description(base_data,
                     zone_description,
                     start_id_col = "start_id",
                     end_id_col = "end_id",
                     zone_id_col = "id")
```


```{r test-add_zone_description}

test_that("The add_zone_description is working",{
  
  # Defing the data to use
  withr::local_seed(123)
  
  base_data <- data.table::data.table(
    start_id = 1:5,
    end_id = sample.int(5, 5),
    value = seq(50, length.out = 5, by = 50)
  )
  
  zone_description <- data.table::data.table(
    id = 1:5,
    City = LETTERS[1:5],
    Zone = tail(LETTERS, 5L)
  )
  
  
  ## Running the function

  # Running the function with defaults
  final_dt <-
    add_zone_description(base_data,
                         zone_description,
                         start_id_col = "start_id",
                         end_id_col = "end_id",
                         zone_id_col = "id")
  
  # Running the function keeping all columns
  final_dt_id <-
    add_zone_description(base_data,
                         zone_description,
                         start_id_col = "start_id",
                         end_id_col = "end_id",
                         zone_id_col = "id",
                         keep_dt_id_cols = TRUE)
  
  # Validating column results
  expect_equal(names(final_dt),
               c("start_city",
                 "start_zone",
                 "end_city",
                 "end_zone",
                 "value"))

  expect_equal(names(final_dt_id),
               c("start_id",
                 "start_city",
                 "start_zone",
                 "end_id",
                 "end_city",
                 "end_zone",
                 "value"))
  
  # Making sure weren't adding rows
  expect_equal(nrow(final_dt), 5L)
  expect_equal(nrow(final_dt_id), 5L)
  
  
  # Validating errors
  
  # We cannot missing start_id_col
  expect_error(add_zone_description(base_data,
                                    zone_description,
                                    start_id_col = "no valid",
                                    end_id_col = "end_id",
                                    zone_id_col = "id"))
  expect_error(add_zone_description(base_data,
                                    zone_description,
                                    start_id_col = c("start_id", "start_id"),
                                    end_id_col = "end_id",
                                    zone_id_col = "id"))
  
  # We cannot missing end_id_col
  expect_error(add_zone_description(base_data,
                                    zone_description,
                                    start_id_col = "start_id",
                                    end_id_col = "no valid",
                                    zone_id_col = "id"))
  expect_error(add_zone_description(base_data,
                                    zone_description,
                                    start_id_col = "start_id",
                                    end_id_col = c("end_id", "end_id"),
                                    zone_id_col = "id"))
  
  # We cannot missing zone_id_col
  expect_error(add_zone_description(base_data,
                                    zone_description,
                                    start_id_col = "start_id",
                                    end_id_col = "end_id",
                                    zone_id_col = "no valid"))
  expect_error(add_zone_description(base_data,
                                    zone_description,
                                    start_id_col = "start_id",
                                    end_id_col = "end_id",
                                    zone_id_col = c("id", "id")))
})
```

## plot_map

```{r function-plot_map}
#' Creates an interactive map with colors
#'
#' @param dt A data.table with the points to show.
#' @param lng_var A character vector indicating the longitude in dt.
#' @param lat_var A character vector indicating the latitude in dt.
#' @param color A character vector to define a custom color for all points.
#' @param color_var A character vector indicating a categorical column in dt.
#' @param color_palette A character selecting the color to use by each level.
#' @param label_var A character vector indicating a categorical column in dt with information .
#' @param map_provider A character vector indicating
#' @param radius A double defining the size of circles to plot.
#' @param radius_var A character vector indicating a numeric column.
#' @param cluster_points If `TRUE` if we have many points it will stop showing all points and showing the sum by sub-regions.
#' 
#' @return An interactive map
#' @export
#'
#' @examples
plot_map <- function(dt,
                     lng_var,
                     lat_var,
                     color = NULL,
                     color_var = NULL,
                     color_palette = NULL,
                     label_var = NULL,
                     map_provider = "CartoDB",
                     radius = 6,
                     radius_var = NULL,
                     cluster_points = FALSE) {
  
  # Selecting base information
  dt_col_names <- names(dt)
  
  ## Assertive programming
  
  # Confirming forming formating
  stopifnot("dt must be a data.table" =
              data.table::is.data.table(dt))
  
  # The variable are in the data
  stopifnot("lng_var and lat_var can not be found in dt" = 
              all(c(lng_var, lat_var) %chin% dt_col_names))
  
  stopifnot("color_var can not be found in dt" = 
              is.null(color_var) || color_var %chin% dt_col_names)
  
  stopifnot("label_var can not be found in dt" = 
              is.null(label_var) || label_var %chin% dt_col_names)
  
  stopifnot("radius_var can not be found in dt" = 
              is.null(radius_var) || radius_var %chin% dt_col_names)
  
    # Confirming we have all information needed
  stopifnot("If you have defined a color_var you also need to define a color_palette" = 
              is.null(color_var) == is.null(color_palette))
  
  
  # If want to show color we need to apply the next steps

  if(!is.null(color_var)) {
    
    color_levels <- names(color_palette)
    
    # Confirming we are selecting a valid values for the palette
    stopifnot("One value couldn't be found in dt" =
                is.null(color_levels) || all(color_levels %chin% unique(dt[[color_var]])))
    
    # Updating data
    dt <-
      dt[color_variable %chin% color_levels,
         env = list(color_variable = color_var)]
    
    # Defining palette
    pal <- leaflet::colorFactor(
      palette = color_palette,
      levels = color_levels
    )
    
  }
  
  pick_values <- function(x, temp_dt = dt) {
    if(is.null(x)) return(x)
    temp_dt[[x]]
  }
  
  # Creating interactive map
  final_map <-
    leaflet::leaflet() |>
    leaflet::addTiles() |>
    leaflet::addProviderTiles(map_provider) |>
    leaflet::addCircleMarkers(
      lng = pick_values(lng_var),
      lat = pick_values(lat_var),
      radius = if(is.null(radius_var)) radius else radius * (pick_values(radius_var) / max(pick_values(radius_var))) ,
      color = if(is.null(color_var)) color else pal(pick_values(color_var)),
      label = pick_values(label_var),
      clusterOptions = if(cluster_points) leaflet::markerClusterOptions() else NULL
    )
  
  # Adding legend when need it
  if(!is.null(color_var)) {
    final_map <- leaflet::addLegend(
      final_map,
      position = "topleft",
      pal = pal,
      values = color_levels
    )
  }

  
  return(final_map)
  
}
```


```{r examples-plot_map}
plot_map(
  ZoneCodesArcgis,
  lng_var = "long",
  lat_var = "lat",
  color_var = "Borough",
  color_palette = c('Manhattan' = '#e41a1c',
                    'Queens' = '#377eb8',
                    'Brooklyn'= '#4daf4a'),
  label_var = "Zone"
)
```

```{r test-plot_map}
test_that("The map works in all situations",{
  
  # The must basic plot
  expect_no_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat"
    )
  })
  
  # Adding color
  expect_no_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat",
      color = "red"
    )
  })
  
  # Adding clusters
  expect_no_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat",
      cluster_points = TRUE
    )
  })
    
  # Adding palette
  expect_no_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat",
      color_var = "Borough",
      color_palette = c('Manhattan' = '#e41a1c',
                        'Queens' = '#377eb8',
                        'Brooklyn'= '#4daf4a')
    )
  })
  
})


test_that("The map shows informative errors",{
  
  # The must basic plot
  expect_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
    )
  },
  regexp = "no default")
  
  expect_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat_error"
    )
  },
  regexp = "can not be found")
    
  # Adding palette
  expect_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat",
      color_palette = c('Manhattan' = '#e41a1c',
                        'Queens' = '#377eb8',
                        'Brooklyn'= '#4daf4a')
    )
  },
  regexp = "you also need to define")
  
  
  expect_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat",
      color_var = "error_col",
      color_palette = c('Manhattan' = '#e41a1c',
                        'Queens' = '#377eb8',
                        'Brooklyn'= '#4daf4a')
    )
  },
  regexp = "can not be found")
  
  
  expect_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat",
      color_var = "Borough",
      color_palette = c('ERROR_VALUE' = '#e41a1c',
                        'Queens' = '#377eb8',
                        'Brooklyn'= '#4daf4a')
    )
  },
  regexp = "couldn't be found")
  
  
  expect_error({
    plot_map(
      ZoneCodesArcgis,
      lng_var = "long",
      lat_var = "lat",
      label_var = "error_var"
    )
  },
  regexp = "can not be found")
  
})

```

## highlight_top_zones

```{r function-highlight_top_zones}
#' Highlight the most repeated zones in a Borough
#'
#' @param dt A `data.table` with the data to use from.
#' @param borough Defines the borough to focus the attention.
#' @param borough_color Defines the base color for the points to show.
#' @param top_color Defines the color to use for the top points.
#' @param top_length Defines the number points to highlight.
#' @param col_prefix Update the following column's names with this prefix.
#' @param borough_col Name of Borough column to filter.
#' @param zone_col Name of column with each zone name.
#' @param long_col Name of column with each zone long.
#' @param lat_col Name of column with each zone lat.
#'
#' @return A leaflet map
#' @export
#'
#' @examples
highlight_top_zones <- function(dt,
                                borough,
                                borough_color = "blue",
                                top_color = "red",
                                top_length = 5L,
                                borough_col = "borough",
                                col_prefix = NULL,
                                zone_col = "zone",
                                long_col = "long",
                                lat_col = "lat") {
  
  legend_name <- paste0("TOP ", top_length)
  
  colors_to_use <- c(top_color, borough_color)
  
  data.table::setattr(colors_to_use, "names", c(legend_name, borough))
  
  if(!is.null(col_prefix)){
    borough_col <- paste0(col_prefix, borough_col)
    zone_col <- paste0(col_prefix, zone_col)
    long_col <- paste0(col_prefix, long_col)
    lat_col <- paste0(col_prefix, lat_col)
  }
  
  zone_dt <-
    dt[borough_exp == borough,
       .(million_trips = sum(n/1e6)),
       by = c(zone_col, long_col, lat_col),
       env = list(borough_exp = borough_col)
    ][!is.na(zone_exp), env = list(zone_exp = zone_col)]
  
  data.table::setorder(zone_dt, -million_trips)
  
  zone_dt[, is_top := borough]
  
  zone_dt[1:top_length, is_top := legend_name]
  
  print(zone_dt[is_top == legend_name, !c("is_top")])
  
  zone_map <- plot_map(
    zone_dt,
    lng_var = long_col,
    lat_var = lat_col,
    color_var = "is_top",
    color_palette = colors_to_use,
    radius = 10,
    radius_var = "million_trips",
    label_var = zone_col
  )
  
  return(zone_map)
  
}
```

## clean_zone_manually

```{r function-clean_zone_manually}
#' Clean zone errors
#' 
#' @description
#' The purpose of this function is correcting wrong locations like happened with:
#' 
#'  - Newark Airport
#'  - Governor's Island
#'  - Ellis Island
#'  - Liberty Island
#'  
#'  It update the zone name to have a name for each location to avoid point overlapping.
#'
#' @param dt A `data.table` with columns `lat`, `long`, `LocationID` and `Zone`.
#'
#' @return A data.table
#' @export
#'
#' @examples
clean_zone_manually <- function(dt) {
  
  stopifnot("dt must be a data.table" = data.table::is.data.table(dt))
  
  stopifnot("dt don't have all columns needed" = 
              all(c("lat", "long", "LocationID", "Zone") %chin% names(dt)))
  
  dt <- data.table::copy(dt)
  
  # Corrected by looking the location on Google Maps
  dt[Zone == "Newark Airport",
     c("lat", "long") := .(40.689499,
                           -74.174484)]
  
  dt[Zone == "Governor's Island", 
     c("lat", 'long') := .(40.68759208028148,
                           -74.02010657167092)]
  
  dt[Zone == "Ellis Island", 
     c("lat", 'long') := .(40.69930943708351,
                           -74.03975375195799)]
  
  dt[Zone == "Liberty Island", 
     c("lat", 'long') := .(40.689975518189954,
                           -74.04541235583368)]
  
  
  # Consolidating Zone names with same locations
  dt[, Zone := data.table::fcase(
    LocationID %in% c(7L, 179L),
    "(Old) Astoria",
    
    LocationID %in% c(21L, 22L),
    "Bensonhurst (East|West)",
    
    LocationID %in% c(36L, 37L),
    "Bushwick (North|South)",
    
    LocationID %in% c(41L, 42L),
    "Central Harlem (North)",
    
    LocationID %in% c(48L, 50L),
    "Clinton (East|West)",
    
    LocationID %in% c(61L, 62L),
    "Crown Heights (North|South)",
    
    LocationID %in% c(71L, 72L),
    "East Flatbush (Farragut|Remsen Village)",
    
    LocationID %in% c(74L, 75L),
    "East Harlem (North|South)",
    
    LocationID %in% c(82L, 83L),
    "Elmhurst (Maspeth)",
    
    LocationID %in% c(87L, 88L),
    "Financial District (North|South)",
    
    LocationID %in% c(113L, 114L),
    "Greenwich Village (North|South)",
    
    LocationID %in% c(140L, 141L),
    "Lenox Hill (East|West)",
    
    LocationID %in% c(142L, 143L),
    "Lincoln Square (East|West)",
    
    LocationID %in% c(158L, 249L),
    "(Meatpacking) West Village",
    
    LocationID %in% c(177L, 178L),
    "Ocean (Hill|Parkway South)",
    
    LocationID %in% c(218L, 219L),
    "Springfield Gardens (North|South)",
    
    LocationID %in% c(227L, 228L),
    "Sunset Park (East|West)",
    
    LocationID %in% c(236L, 237L),
    "Upper East Side (North|South)",
    
    LocationID %in% c(238L, 239L),
    "Upper West Side (North|South)",
    
    LocationID %in% c(262L, 263L),
    "Yorkville (East|West)",
    
    LocationID %in% c(264L, 265L),
    "NA",
    
    rep(TRUE, times = .N), 
    Zone
  )]
  
  return(dt)
  
}
```

```{r test-clean_zone_manually}

test_that("Several zones represed as a single location", {
  
  clean_dt <- clean_zone_manually(ZoneCodesArcgis)
  
  # the zones cannot be empty
  expect_false(any(is.na(clean_dt$Zone)))
  
  
  expect_equal(
    clean_dt[, .(zone_count = data.table::uniqueN(Zone)),
             c("long", 'lat')
    ][zone_count > 1L, .N],
    0L
  )
  
})

```



## factor_weekday

```{r function-factor_weekday}
#' Transform number into factors
#'
#' Transform a numeric vector in factor with a level for each day of a week.
#'
#' @param x A numeric vector with values from 1 to 7
#'
#' @return A factor vector
#' @export
#'
#' @examples
factor_weekday <- function(x){
  
  stopifnot("The vector must be numeric" = is.numeric(x))
  
  if(!all(x %in% 1:7)){
    warning("One of the number is not from 1 to 7")
  }

  weekdays_name <- c("Mo", "Tu", "We", "Th", "Fr", "Sa", "Su")

  factor(weekdays_name[x], levels = weekdays_name)

}
```

```{r example-factor_weekday}

factor_weekday(c(1,7,5))

```


```{r test-factor_weekday}

test_that("x must be numeric",{
  testthat::expect_error(factor_weekday(c("Mon", 5)))
})

test_that("x must have values from 1 to 7",{
  testthat::expect_warning(factor_weekday(c(10, 5)))
})

```

## compute_num_summary

```{r function-compute_num_summary}
#' Calculates all values need to describe
#' 
#' Calculates of values needed to create a boxplot.
#'
#' @param x A data.frame or an arrow connection
#' @param value A column vector to summarize
#'
#' @return A data.frame with summary values
#' @export
#'
#' @examples
compute_num_summary <- function(x, value){

  summary <-
    dplyr::filter(x,
                  !is.na({{value}})) |>
    dplyr::summarize(min_value = min({{value}}),
                     q1 = quantile({{value}}, 0.25),
                     q2 = median({{value}}),
                     mean = mean({{value}}),
                     q3 = quantile({{value}}, 0.75),
                     max_value = max({{value}}),
                     sd = sd({{value}})) |>
    dplyr::mutate(lower_whisker = q1 - 1.5*(q3 - q1),
                  higher_whisker = q3 + 1.5*(q3 - q1)) |>
    dplyr::select(sd,
                  min_value,
                  lower_whisker,
                  q1,
                  q2,
                  mean,
                  q3,
                  higher_whisker,
                  max_value)
  
  if(is_arrow_con(x)){
    summary <- dplyr::collect(summary)
  }

  return(summary)
}
```


```{r example-compute_num_summary}

data.frame(x = rnorm(200, mean = 5)) |>
  arrow::arrow_table() |>
  compute_num_summary(x)

```

## ZoneCodesArcgis

```{r function-ZoneCodesArcgis, eval=FALSE, echo=FALSE}
#' ZoneCodesArcgis
#'
#' Describe the locations used in the main data.
#'
#' @format A data frame of 7 variables:
#' \describe{
#'   \item{ LocationID }{ An unique id realted to each location}
#'   \item{ Borough }{ Borough for the location }
#'   \item{ Zone }{ Zone for the location }
#'   \item{ service_zone }{ Define the zone type }
#'   \item{ Address }{ A complete address for each location }
#'   \item{ lat }{ A latitute estimation based on Address }
#'   \item{ long }{ A longitute estimation based on Address }
#' }
#' @source TLC Trip Record Data and Arcgis
"ZoneCodesArcgis"
```


# Sampling

## sample_parquet

```{r function-sample_parquet}
#' Take a sample from a parquet file
#'
#' @param file_path A character file name or URI.
#' @param valid_zones A vector of zones of the trips you want to sample from.
#' @param prob The proportion of rows to keep in the sample.
#' @param seed Number to keep the sample reprodicible.
#' 
#' @return A data.table
#' @export
#'
#' @examples
sample_parquet <- function(file_path,
                           valid_zones = NULL,
                           prob = 0.05,
                           seed = 1){
  
  
raw_data <- arrow::read_parquet(file_path)

data.table::setDT(raw_data)

withr::local_seed(seed)

if(is.null(valid_zones)) {
  
  sampled_data <-
    raw_data[, .SD[sample.int(.N, size = as.integer(.N * prob))]]
  
  return(sampled_data)
  
}

sampled_data <-
  raw_data[.(valid_zones),
           on = "PULocationID",
           nomatch = 0
  ][.(valid_zones),
    on = "DOLocationID",
    nomatch = 0
  ][, .SD[sample.int(.N, size = as.integer(.N * prob))]]

return(sampled_data)
  
}

```

```{r example-sample_parquet}
df <- data.frame(x = 1:100)
file_path <- tempfile(fileext = ".parquet")

arrow::write_parquet(df, file_path)

sample_parquet(file_path)
```

```{r test-sample_parquet}
test_that("The prob is working",{
  df <- data.frame(x = 1:100)
  file_path <- tempfile(fileext = ".parquet")
  
  arrow::write_parquet(df, file_path)
  
  taken_sample <- sample_parquet(file_path)
  
  expect_equal(nrow(taken_sample),5L)
  
  file.remove(file_path)
})

test_that("The zone is working",{
  
  withr::local_seed(100)
  
  df <- data.frame(x = 1:100,
                   PULocationID = sample.int(3L, 100, TRUE),
                   DOLocationID = sample.int(3L, 100, TRUE))
  
  file_path <- withr::local_tempfile(fileext = ".parquet")
  
  arrow::write_parquet(df, file_path)
  
  valid_zones <-  c(2L, 3L)
  
  taken_sample <- sample_parquet(file_path,
                                 valid_zones = valid_zones,
                                 prob = 0.10)
  
  # Start and End in valid zone
  expect_true(all(taken_sample$PULocationID %in% valid_zones))
  expect_true(all(taken_sample$DOLocationID %in% valid_zones))
  
  # We don't need NA zones
  expect_false(any(is.na(taken_sample$PULocationID)))
  expect_false(any(is.na(taken_sample$DOLocationID)))
  
  # We don't always end where we started
  expect_true(any(taken_sample$DOLocationID != taken_sample$PULocationID))
})
```


# Transformation

## apply_base_cleaning


```{r function-apply_base_cleaning}
#' Apply the transformations based on initial EDA
#'
#' @param dt A data.table with all columns of data and after translating the code zone with their meaning.
#'
#' @return A data.table
#' @export
#' 
#' @examples
apply_base_cleaning <- function(dt) {
  
  # Transforming columns into factors
  
  dt[, company := 
       data.table::fcase(hvfhs_license_num == "HV0002", "Juno",
                         hvfhs_license_num == "HV0003", "Uber",
                         hvfhs_license_num == "HV0004", "Via",
                         hvfhs_license_num == "HV0005", "Lyft") |>
       factor(levels = c("Juno", "Uber", "Via", "Lyft"))]
  
  dt[, dispatching_base_num :=
       data.table::fifelse(dispatching_base_num %chin% c("B03404", "B03406"),
                           dispatching_base_num,
                           "Other") |>
       factor(levels = c("B03404", "B03406", "Other"))]
  
  dt[, originating_base_num := 
       data.table::fcase(is.na(dispatching_base_num), "Missing", 
                         dispatching_base_num == "B03404", "B03404",
                         default = "Other") |>
       factor(levels = c("B03404", "Other", "Missing"))]
  
  
  # Selecting column groups
  
  col_names <- names(dt)
  flag_cols <- grep("flag$", col_names, value = TRUE)
  borough_cols <- grep("borough$", col_names, value = TRUE)
  service_zone_cols <- grep("service_zone$", col_names, value = TRUE)
  
  
  # Formating columns by group
  
  dt[, (flag_cols) := lapply(
    .SD,
    FUN = \(x) data.table::fifelse(x %chin% c("Y", "N"), x, "Missing") |>
      factor(levels = c("Y", "N", "Missing"))
  ),
  .SDcols = flag_cols]
  

  dt[, (borough_cols) := lapply(
    .SD,
    FUN = \(x) factor(x, levels = c("Manhattan", "Brooklyn", "Queens"))
  ),
  .SDcols = borough_cols]


  dt[, (service_zone_cols) := lapply(
    .SD,
    FUN = \(x) factor(x, levels = c("Boro Zone", "Yellow Zone", "Airports"))
  ),
  .SDcols = service_zone_cols]

  
  # Defining same place
  
  dt[, same_borough := start_borough == end_borough]
  dt[, same_service_zone := start_service_zone == end_service_zone]
  dt[, same_zone := start_zone == end_zone]
  
  
  # Some times the request time is higher than
  # the drop off time it seems it was an exchange 
  # between both columns
  dt[, `:=`(dropoff_datetime = pmax(dropoff_datetime, request_datetime),
            request_datetime = pmin(dropoff_datetime, request_datetime))]
  
  # Adding numeric columns
  
  dt[, trip_minutes := 
       difftime(dropoff_datetime,
                request_datetime,
                units = "mins") |>
       as.integer()]
    
    dt[, profit_rate := 
         (driver_pay + tips) / (trip_minutes / 60L)]

    
  # Defining columns to keep
  
    cols_to_keep <- c(
      "company",
      "dispatching_base_num",
      "originating_base_num",
      flag_cols,
      borough_cols,
      service_zone_cols,
      "start_lat",
      "start_long",
      "end_lat",
      "end_long",
      "same_borough",
      "same_service_zone",
      "same_zone",
      "base_passenger_fare",
      "trip_miles",
      "request_datetime",
      "dropoff_datetime",
      "trip_minutes",
      "tips",
      "driver_pay",
      "profit_rate"
    )
  
  # We don't canceled trips and we want this new col order
  return(dt[trip_minutes != 0L, ..cols_to_keep])
  
}
```

```{r examples-apply_base_cleaning}

data.table::data.table(hvfhs_license_num = "HV0004",
                       dispatching_base_num = "HOLA",
                       originating_base_num = NA_character_,
                       access_a_ride_flag = "",     
                       shared_request_flag = "Y",
                       shared_match_flag = "Y",
                       wav_request_flag = "Y",
                       wav_match_flag = "Y",
                       start_borough = "Manhattan",
                       end_borough = "Brooklyn",
                       start_service_zone = "Boro Zone",
                       end_service_zone = "Yellow Zone",
                       start_zone = "1",
                       end_zone = "2",
                       base_passenger_fare = 800,
                       trip_miles = 250,
                       request_datetime = as.POSIXct("2022-05-18 7:25:00"), 
                       dropoff_datetime = as.POSIXct("2022-05-18 8:15:00"),
                       tips = 500,
                       driver_pay = 800) |>
  apply_base_cleaning()

```


## add_datetime_features

```{r function-add_datetime_features}
#' Add more features to explain a date
#'
#' @param df A data.frame with datetime column to use.
#' @param date_col A string to define the column to be use
#' 
#' @return A data.frame with the new features.
#' @export
#'
#' @examples
add_datetime_features <- function(df, date_col) {
  
  col_expr <- rlang::sym(date_col)
  
  cyclic_df <- 
    lubridate::cyclic_encoding(df[[date_col]],
                               periods = c("day", "week", "month")) |>
    as.data.frame()
  
  data.table::setattr(cyclic_df, "names", paste0(date_col, "_", names(cyclic_df)))
  
  df_cleaned <- cbind(df, cyclic_df)
  
  df_cleaned <-
    recipes::recipe(profit_rate ~ .,
                    data = df_cleaned) |>
    recipes::step_date({{col_expr}},
                       features = c("dow",
                                    "doy",
                                    "week",
                                    "month",
                                    "decimal",
                                    "quarter",
                                    "semester")) |>
    recipes::step_time({{col_expr}},
                       features = c("am", 
                                    "hour",
                                    "hour12",
                                    "decimal_day")) |>
    recipes::step_holiday({{col_expr}},
                          holidays = timeDate::listHolidays("^US"),
                          keep_original_cols = FALSE) |>
    recipes::prep(training = df_cleaned) |>
    recipes::bake(new_data = NULL)
  
  return(df_cleaned)
  
}
```

```{r examples-add_datetime_features}
data.frame(profit_rate = 15,
           x = as.POSIXct("2024-05-18 08:00:15"),
           y = as.POSIXct("2024-07-04 08:00:15")) |>
  add_datetime_features(date_col = "x") |>
  add_datetime_features(date_col = "y")
```

# Inflate the functions

```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly

c("R", "man", "tests/testthat") |>
  sapply(FUN = list.files,
         pattern = "\\.Rd?", 
         full.names = TRUE) |>
  unlist() |>
  setdiff(y = "R/project.nyc.taxi-package.R") |>
  file.remove()

fusen::inflate(flat_file = "dev/flat_functions.Rmd", 
               vignette_name = NA,
               vignettes = FALSE,
               check = FALSE)
```

```{r development-creating-package-file, eval=TRUE}
readLines("dev/flat_functions.Rmd") |>
  stringr::str_subset(pattern = "@importFrom") |>
  stringr::str_remove(pattern = "#' @importFrom ") |>
  stringr::str_match(pattern = "^(.+?) (.+?)$") |>
  (\(x) data.table::data.table(id = 1:nrow(x),
                               package = x[,2],
                               functions = strsplit(x[,3]," ", TRUE)))() |>
  (\(dt) dt[, .(functions = functions[[1L]] |> stringr::str_remove_all("`")),
            by = c("id", "package")])() |>
  (\(dt) dt[, usethis::use_import_from(package = package, unique(functions)),
            by = "package"])()
```



```{r development-building-website, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly

remove.packages("project.nyc.taxi")

rstudioapi::restartSession()

install_local()

#pkgdown::build_site()
pkgdown::build_reference()
pkgdown::build_article("03-data-understanding")
```


```yml
reference:
  - title: Bussiness Understanding
    contents:
    - simulate_trips
    - BaseLineSimulation
  - title: Data Understanding
    contents:
    - fast_glimpse
    - count_pct
    - add_zone_description
    - factor_weekday
    - compute_num_summary
    - summary_to_boxplot
```

